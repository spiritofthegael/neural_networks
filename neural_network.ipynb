{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for array-handling and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "# for testing on CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Activation('tanh'))                            \n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512))\n",
    "model.add(tf.keras.layers.Activation('tanh'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 13s - loss: 0.3121 - accuracy: 0.9054 - val_loss: 0.1577 - val_accuracy: 0.9509\n",
      "Epoch 2/20\n",
      "469/469 - 12s - loss: 0.1544 - accuracy: 0.9531 - val_loss: 0.1196 - val_accuracy: 0.9606\n",
      "Epoch 3/20\n",
      "469/469 - 12s - loss: 0.1164 - accuracy: 0.9639 - val_loss: 0.0957 - val_accuracy: 0.9696\n",
      "Epoch 4/20\n",
      "469/469 - 12s - loss: 0.0943 - accuracy: 0.9704 - val_loss: 0.0894 - val_accuracy: 0.9722\n",
      "Epoch 5/20\n",
      "469/469 - 12s - loss: 0.0821 - accuracy: 0.9737 - val_loss: 0.0866 - val_accuracy: 0.9721\n",
      "Epoch 6/20\n",
      "469/469 - 14s - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.0873 - val_accuracy: 0.9725\n",
      "Epoch 7/20\n",
      "469/469 - 13s - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0837 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "469/469 - 13s - loss: 0.0563 - accuracy: 0.9823 - val_loss: 0.0643 - val_accuracy: 0.9783\n",
      "Epoch 9/20\n",
      "469/469 - 14s - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.0723 - val_accuracy: 0.9782\n",
      "Epoch 10/20\n",
      "469/469 - 15s - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.0883 - val_accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "469/469 - 14s - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0766 - val_accuracy: 0.9772\n",
      "Epoch 12/20\n",
      "469/469 - 14s - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0807 - val_accuracy: 0.9783\n",
      "Epoch 13/20\n",
      "469/469 - 15s - loss: 0.0395 - accuracy: 0.9869 - val_loss: 0.0924 - val_accuracy: 0.9770\n",
      "Epoch 14/20\n",
      "469/469 - 14s - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.0793 - val_accuracy: 0.9777\n",
      "Epoch 15/20\n",
      "469/469 - 13s - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.0759 - val_accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "469/469 - 12s - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.0866 - val_accuracy: 0.9774\n",
      "Epoch 17/20\n",
      "469/469 - 12s - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0733 - val_accuracy: 0.9813\n",
      "Epoch 18/20\n",
      "469/469 - 12s - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "469/469 - 12s - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0841 - val_accuracy: 0.9775\n",
      "Epoch 20/20\n",
      "469/469 - 12s - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0773 - val_accuracy: 0.9800\n",
      "Saved trained model at results/keras_mnist.h5 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x1400 with 2 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model and saving metrics in history\n",
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# saving the model\n",
    "save_dir = \"results/\"\n",
    "model_name = 'keras_mnist.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# plotting the metrics\n",
    "fig = plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0773 - accuracy: 0.9800\n",
      "Test Loss 0.07734496146440506\n",
      "Test Accuracy 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "mnist_model = tf.keras.models.load_model(model_path)\n",
    "loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9800  classified correctly\n",
      "200  classified incorrectly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x1400 with 18 Axes>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and create predictions on the test set\n",
    "mnist_model = tf.keras.models.load_model(model_path)\n",
    "predicted_classes = mnist_model.predict_classes(X_test)\n",
    "\n",
    "# see which we predicted correctly and which not\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "# adapt figure size to accomodate 18 subplots\n",
    "plt.rcParams['figure.figsize'] = (7,14)\n",
    "\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted: {}, Truth: {}\".format(predicted_classes[correct],\n",
    "                                        y_test[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# plot 9 incorrect predictions\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(6,3,i+10)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted {}, Truth: {}\".format(predicted_classes[incorrect], \n",
    "                                       y_test[incorrect]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "figure_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data: \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Example labels: \n",
      "[0 0 0 0 0]\n",
      "Neural Network Model Summary: \n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "24/24 - 0s - loss: 3.7464 - accuracy: 0.2917\n",
      "Epoch 2/20\n",
      "24/24 - 0s - loss: 2.0993 - accuracy: 0.2833\n",
      "Epoch 3/20\n",
      "24/24 - 0s - loss: 1.5470 - accuracy: 0.0250\n",
      "Epoch 4/20\n",
      "24/24 - 0s - loss: 1.3274 - accuracy: 0.2083\n",
      "Epoch 5/20\n",
      "24/24 - 0s - loss: 1.1158 - accuracy: 0.3583\n",
      "Epoch 6/20\n",
      "24/24 - 0s - loss: 0.9813 - accuracy: 0.3583\n",
      "Epoch 7/20\n",
      "24/24 - 0s - loss: 0.8900 - accuracy: 0.5167\n",
      "Epoch 8/20\n",
      "24/24 - 0s - loss: 0.8028 - accuracy: 0.7167\n",
      "Epoch 9/20\n",
      "24/24 - 0s - loss: 0.7329 - accuracy: 0.8417\n",
      "Epoch 10/20\n",
      "24/24 - 0s - loss: 0.6639 - accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "24/24 - 0s - loss: 0.6148 - accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "24/24 - 0s - loss: 0.5757 - accuracy: 0.8250\n",
      "Epoch 13/20\n",
      "24/24 - 0s - loss: 0.5412 - accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "24/24 - 0s - loss: 0.5123 - accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "24/24 - 0s - loss: 0.4912 - accuracy: 0.8417\n",
      "Epoch 16/20\n",
      "24/24 - 0s - loss: 0.4665 - accuracy: 0.8417\n",
      "Epoch 17/20\n",
      "24/24 - 0s - loss: 0.4509 - accuracy: 0.8917\n",
      "Epoch 18/20\n",
      "24/24 - 0s - loss: 0.4339 - accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "24/24 - 0s - loss: 0.4182 - accuracy: 0.9167\n",
      "Epoch 20/20\n",
      "24/24 - 0s - loss: 0.3988 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8333\n",
      "Final test set loss: 0.506481\n",
      "Final test set accuracy: 0.833333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "iris_data = load_iris() \n",
    "\n",
    "print('Example data: ')\n",
    "print(iris_data.data[:5])\n",
    "print('Example labels: ')\n",
    "print(iris_data.target[:5])\n",
    "\n",
    "x = iris_data.data\n",
    "y_ = iris_data.target.reshape(-1, 1) \n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "# Build the model\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Activation('relu'))    \n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(3))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_x, train_y, verbose=2, batch_size=5, epochs=20)\n",
    "\n",
    "# Test on unseen data\n",
    "\n",
    "results = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
