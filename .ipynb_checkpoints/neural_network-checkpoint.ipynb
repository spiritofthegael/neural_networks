{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for array-handling and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "# for testing on CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(18, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Activation('relu'))                            \n",
    "\n",
    "model.add(tf.keras.layers.Dense(18))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 2s - loss: 0.6150 - accuracy: 0.8199 - val_loss: 0.2945 - val_accuracy: 0.9169\n",
      "Epoch 2/20\n",
      "469/469 - 2s - loss: 0.2695 - accuracy: 0.9238 - val_loss: 0.2297 - val_accuracy: 0.9339\n",
      "Epoch 3/20\n",
      "469/469 - 2s - loss: 0.2188 - accuracy: 0.9388 - val_loss: 0.2055 - val_accuracy: 0.9377\n",
      "Epoch 4/20\n",
      "469/469 - 2s - loss: 0.1901 - accuracy: 0.9454 - val_loss: 0.1779 - val_accuracy: 0.9474\n",
      "Epoch 5/20\n",
      "469/469 - 2s - loss: 0.1706 - accuracy: 0.9514 - val_loss: 0.1634 - val_accuracy: 0.9503\n",
      "Epoch 6/20\n",
      "469/469 - 2s - loss: 0.1558 - accuracy: 0.9555 - val_loss: 0.1565 - val_accuracy: 0.9536\n",
      "Epoch 7/20\n",
      "469/469 - 2s - loss: 0.1441 - accuracy: 0.9580 - val_loss: 0.1466 - val_accuracy: 0.9565\n",
      "Epoch 8/20\n",
      "469/469 - 2s - loss: 0.1358 - accuracy: 0.9607 - val_loss: 0.1413 - val_accuracy: 0.9560\n",
      "Epoch 9/20\n",
      "469/469 - 2s - loss: 0.1276 - accuracy: 0.9629 - val_loss: 0.1451 - val_accuracy: 0.9560\n",
      "Epoch 10/20\n",
      "469/469 - 2s - loss: 0.1224 - accuracy: 0.9647 - val_loss: 0.1421 - val_accuracy: 0.9578\n",
      "Epoch 11/20\n",
      "469/469 - 2s - loss: 0.1163 - accuracy: 0.9657 - val_loss: 0.1403 - val_accuracy: 0.9564\n",
      "Epoch 12/20\n",
      "469/469 - 2s - loss: 0.1120 - accuracy: 0.9670 - val_loss: 0.1335 - val_accuracy: 0.9609\n",
      "Epoch 13/20\n",
      "469/469 - 2s - loss: 0.1076 - accuracy: 0.9688 - val_loss: 0.1357 - val_accuracy: 0.9595\n",
      "Epoch 14/20\n",
      "469/469 - 2s - loss: 0.1037 - accuracy: 0.9688 - val_loss: 0.1372 - val_accuracy: 0.9598\n",
      "Epoch 15/20\n",
      "469/469 - 2s - loss: 0.1006 - accuracy: 0.9701 - val_loss: 0.1315 - val_accuracy: 0.9603\n",
      "Epoch 16/20\n",
      "469/469 - 2s - loss: 0.0968 - accuracy: 0.9711 - val_loss: 0.1341 - val_accuracy: 0.9604\n",
      "Epoch 17/20\n",
      "469/469 - 2s - loss: 0.0957 - accuracy: 0.9712 - val_loss: 0.1266 - val_accuracy: 0.9621\n",
      "Epoch 18/20\n",
      "469/469 - 2s - loss: 0.0907 - accuracy: 0.9733 - val_loss: 0.1318 - val_accuracy: 0.9617\n",
      "Epoch 19/20\n",
      "469/469 - 2s - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.1337 - val_accuracy: 0.9605\n",
      "Epoch 20/20\n",
      "469/469 - 2s - loss: 0.0878 - accuracy: 0.9741 - val_loss: 0.1327 - val_accuracy: 0.9621\n",
      "Saved trained model at results/keras_mnist5.h5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-a7ec4e790f3c>:34: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# training the model and saving metrics in history\n",
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# saving the model\n",
    "save_dir = \"results/\"\n",
    "model_name = 'keras_mnist5.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# plotting the metrics\n",
    "fig = plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1327 - accuracy: 0.9621\n",
      "Test Loss 0.13269825279712677\n",
      "Test Accuracy 0.9621000289916992\n"
     ]
    }
   ],
   "source": [
    "mnist_model = tf.keras.models.load_model(model_path)\n",
    "loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9575  classified correctly\n",
      "425  classified incorrectly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x1400 with 18 Axes>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and create predictions on the test set\n",
    "mnist_model = tf.keras.models.load_model(model_path)\n",
    "predicted_classes = mnist_model.predict_classes(X_test)\n",
    "\n",
    "# see which we predicted correctly and which not\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "# adapt figure size to accomodate 18 subplots\n",
    "plt.rcParams['figure.figsize'] = (7,14)\n",
    "\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted: {}, Truth: {}\".format(predicted_classes[correct],\n",
    "                                        y_test[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# plot 9 incorrect predictions\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(6,3,i+10)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted {}, Truth: {}\".format(predicted_classes[incorrect], \n",
    "                                       y_test[incorrect]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "figure_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data: \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Example labels: \n",
      "[0 0 0 0 0]\n",
      "Neural Network Model Summary: \n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "24/24 - 0s - loss: 3.7464 - accuracy: 0.2917\n",
      "Epoch 2/20\n",
      "24/24 - 0s - loss: 2.0993 - accuracy: 0.2833\n",
      "Epoch 3/20\n",
      "24/24 - 0s - loss: 1.5470 - accuracy: 0.0250\n",
      "Epoch 4/20\n",
      "24/24 - 0s - loss: 1.3274 - accuracy: 0.2083\n",
      "Epoch 5/20\n",
      "24/24 - 0s - loss: 1.1158 - accuracy: 0.3583\n",
      "Epoch 6/20\n",
      "24/24 - 0s - loss: 0.9813 - accuracy: 0.3583\n",
      "Epoch 7/20\n",
      "24/24 - 0s - loss: 0.8900 - accuracy: 0.5167\n",
      "Epoch 8/20\n",
      "24/24 - 0s - loss: 0.8028 - accuracy: 0.7167\n",
      "Epoch 9/20\n",
      "24/24 - 0s - loss: 0.7329 - accuracy: 0.8417\n",
      "Epoch 10/20\n",
      "24/24 - 0s - loss: 0.6639 - accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "24/24 - 0s - loss: 0.6148 - accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "24/24 - 0s - loss: 0.5757 - accuracy: 0.8250\n",
      "Epoch 13/20\n",
      "24/24 - 0s - loss: 0.5412 - accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "24/24 - 0s - loss: 0.5123 - accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "24/24 - 0s - loss: 0.4912 - accuracy: 0.8417\n",
      "Epoch 16/20\n",
      "24/24 - 0s - loss: 0.4665 - accuracy: 0.8417\n",
      "Epoch 17/20\n",
      "24/24 - 0s - loss: 0.4509 - accuracy: 0.8917\n",
      "Epoch 18/20\n",
      "24/24 - 0s - loss: 0.4339 - accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "24/24 - 0s - loss: 0.4182 - accuracy: 0.9167\n",
      "Epoch 20/20\n",
      "24/24 - 0s - loss: 0.3988 - accuracy: 0.9583\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8333\n",
      "Final test set loss: 0.506481\n",
      "Final test set accuracy: 0.833333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "iris_data = load_iris() \n",
    "\n",
    "print('Example data: ')\n",
    "print(iris_data.data[:5])\n",
    "print('Example labels: ')\n",
    "print(iris_data.target[:5])\n",
    "\n",
    "x = iris_data.data\n",
    "y_ = iris_data.target.reshape(-1, 1) \n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Activation('relu'))    \n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(3))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(train_x, train_y, verbose=2, batch_size=5, epochs=20)\n",
    "\n",
    "\n",
    "\n",
    "results = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
